---
title: "Practical machine learning course project"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r knitr_setup, echo=FALSE}

# Global R markdown code chunk options
knitr::opts_chunk$set(message=FALSE, 
                      warning = FALSE, 
                      error=FALSE, 
                      echo=TRUE, 
                      fig.width = 7, fig.height = 6, 
                      fig.align = 'left')
```

# 1. Project description

**Background**     

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

**Data**    
The training data for this project are available here:    

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv    

The test data are available here:    

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv    

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment. 

**What you should submit**     

The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases. 

# 2. Summary of the approach

## 2.1 Data split

Data split pml-training.csv dataset consists of 19622 observation. I decided to split this data set dedicating 75% of the records to testing, and 25% to testing or model validation. The pml-testing.csv data set has only been used for applying the validated model.


## 2.2 Data cleaning

* Only predictors containing measurements from accelerometers on the belt, forearm, arm, and dumbell have been used for modeling.   

* Predictors containing missing data have been excluded. None of the 52 predictors had near zero variance.


## 2.3 Model building and validation

Using the training data set I built three models:  
1) random forest      
2) gradient boosting machine     
3) linear discriminant analysis   

Parallel computing framework, using doParallel package, was used to accelerate the computations. 

**Out of sample error**
Model accuracy was measured using a 25% subset of the test data. 

* Random forest had the highest accuracy of 99.5%, with the lowest out of sample error of only 0.5%.        

* The gradient boosting machine model had very high accuracy of 96.9%, with 3.1% out of sample error.    

* Linear discriminant analysis achieved only 69.7% accuracy and 30.3% out of sample error. Higher error in this model is expected because it assumes normal distribution.  

## 2.4 Model application

Random forest and gradient boosting machine produced identical predictions for 20 cases in the pml-testing.csv data set. 


# 3. Execution

# 3.1 Read the data

```{r}

set.seed(1234)  # Seed has been set for reproducibility

# Read training data
train_df <- read.csv("pml-training.csv")

# Read data set with 20 cases to predicte the outcome for
application_df <- read.csv("pml-testing.csv") 


#dim(train_df)      # 19622   160
#dim(application_df) # 20 160

```

## 3.1 Data cleaning

I'm using only predictors from accelerometers on the belt, forearm, arm, and dumbell.
```{r}

# Keep only variables including classe|belt|forearm|arm|dumbbell in the name
train_df <- train_df[,grep("classe|belt|forearm|arm|dumbbell", colnames(train_df), value = TRUE)]

#dim(train_df) # 19622   153

```


Clean the data removing variables containing missing records
```{r}

# Remove variables with NAs or missing observations

#train_df2 <- train_df[, sapply(train_df, function (x) all(complete.cases(x)))]
#str(train_df2)
# The solution above keeps 86 variables, but many of them contain "" entries

# This is a much more conservative approach, keeping 53 variables. It removes predictors containing NAs and "". 
train_df <- train_df[, !sapply(train_df, function (x) any(is.na(x) | x == ""))]

#dim(train_df) # 19622 53

```

Inspect the data
```{r}
str(train_df)

```



```{r}

# Use the same set of variables in the application_df dataset.

application_df <- application_df[, colnames(application_df) %in% colnames(train_df)]

#dim(application_df) # 20 52

```



## 3.2 Training machine learning models

```{r, eval=FALSE}

# Change the class of the classe variable from character to factor.
train_df$classe <- as.factor(train_df$classe)

library(randomForest)
library(caret)

# Split the data dedicating 75% of measurements to model building, and 25% for model validation.
inTrain = createDataPartition(train_df$classe, p = 0.75)[[1]]
training = train_df[inTrain,]
testing = train_df[-inTrain,]


#dim(training) # 14718   53
#dim(testing)  # 4904  53


################## Build models ##################

library(doParallel)
cl<-makePSOCKcluster(3)
registerDoParallel(cl)

## Random forest
mod_rf <- train(classe ~ ., data = training, method = "rf")

## Gradient Boosting Machine
mod_gbm <- train(classe ~ ., data = training, method = "gbm")

## Linear discriminant analysis
mod_lda <- train(classe ~ ., data = training, method = "lda")

stopCluster(cl)

## Ensure that the multicore cluster is terminated
# https://stackoverflow.com/questions/64519640/error-in-summary-connectionconnection-invalid-connection
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}

unregister_dopar()
###

# Save R session image to speep up knitting the document.
save.image("./Trained_models_6_25_2022.RData")

```


## 3.3 Predict class variable from the testing data
```{r}

library(caret)

load("./Trained_models_6_25_2022.RData")

# Predict
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)

```


## 3.4 Assess models performance

**Random forest:**

Model accuracy:
```{r}
# Accuracy using random forests 0.9949021 
confusionMatrix(pred_rf, testing$classe)$overall[1]
```

Out of sample error:
```{r}
1 - as.numeric(confusionMatrix(pred_rf, testing$classe)$overall[1])
```

**Gradient boosting machine:**

Model accuracy:
```{r}
# Accuracy using boosting 0.968801
confusionMatrix(pred_gbm, testing$classe)$overall[1]
```

Out of sample error:
```{r}
1 - as.numeric(confusionMatrix(pred_gbm, testing$classe)$overall[1])
```

**Linear discriminant analysis:**

Model accuracy:
```{r}
# Accuracy using linear discriminant analysis 0.6969821   
confusionMatrix(pred_lda, testing$classe)$overall[1]
```

Out of sample error:
```{r}
1 - as.numeric(confusionMatrix(pred_lda, testing$classe)$overall[1])
```


## 3.5 Apply model to pml-testing.csv dataset

```{r}

# Predict the class
pred_rf_applied <- predict(mod_rf, application_df)
pred_gbm_applied <- predict(mod_gbm, application_df)
pred_lda_applied <- predict(mod_lda, application_df)


# Add predicted values the the dataset
application_df$classe_rf_pred <- pred_rf_applied
application_df$classe_gbm_pred <- pred_gbm_applied
application_df$classe_lda_pred <- pred_lda_applied
```

Random forest and gradient boosting machine models produce identical predictions. This is consistent with very high accuracy/ very low out of sample error of these models.
```{r}
all(application_df$classe_rf_pred == application_df$classe_gbm_pred)  # Identical
```

Predictions generated by the linear discriminant analysis are only 65% identical as predictions generated by the random forest model. 
```{r}

sum(application_df$classe_rf_pred == application_df$classe_lda_pred) / length(application_df$classe_lda_pred)

```

